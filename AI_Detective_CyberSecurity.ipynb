{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPg1s+VQ1JBviZ3Mv8WMo9E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enasshalolh/my_coulb_project/blob/main/AI_Detective_CyberSecurity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "📌 Step 1: Understanding the Dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "YrHn30kplCnd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_3EQlMFk6kx",
        "outputId": "6aca838d-4e84-4361-9410-cf277cd005b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of the dataset:\n",
            "             timestamp  user_id  network_speed  files_accessed  \\\n",
            "0  2024-01-01 00:00:00     1102             19              22   \n",
            "1  2024-01-01 01:00:00     1435             25              18   \n",
            "2  2024-01-01 02:00:00     1860             80              30   \n",
            "3  2024-01-01 03:00:00     1270             26               4   \n",
            "4  2024-01-01 04:00:00     1106             32              18   \n",
            "\n",
            "   suspicious_score  attack_flag  device_type_Laptop  device_type_Mobile  \\\n",
            "0          0.142137            0                   1                   0   \n",
            "1          0.011707            0                   1                   0   \n",
            "2          0.422034            0                   0                   1   \n",
            "3          0.295041            0                   0                   0   \n",
            "4          0.486000            0                   1                   0   \n",
            "\n",
            "   device_type_Tablet  \n",
            "0                   0  \n",
            "1                   0  \n",
            "2                   0  \n",
            "3                   1  \n",
            "4                   0  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "# تحميل ملف البيانات\n",
        "df = pd.read_csv(\"cyber_data.csv\")\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "📌 Step 2: Data Preprocessing"
      ],
      "metadata": {
        "id": "dW2JCfJalOuO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "I1uwjpYzk7uX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# التحقق من القيم المفقودة في البيانات\n",
        "missing_values = df.isnull().sum()\n",
        "print(\"Missing values in each column:\")\n",
        "print(missing_values)\n",
        "\n",
        "# حذف الأعمدة غير الضرورية\n",
        "df_cleaned = df.drop(columns=[\"timestamp\", \"user_id\"])  # إزالة الأعمدة التي لا تؤثر على التصنيف\n",
        "\n",
        "print(\"First 5 rows after preprocessing:\")\n",
        "print(df_cleaned.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkqPz-lklagO",
        "outputId": "72ba7780-7422-4fb8-f739-38b53a6b6438"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in each column:\n",
            "timestamp             0\n",
            "user_id               0\n",
            "network_speed         0\n",
            "files_accessed        0\n",
            "suspicious_score      0\n",
            "attack_flag           0\n",
            "device_type_Laptop    0\n",
            "device_type_Mobile    0\n",
            "device_type_Tablet    0\n",
            "dtype: int64\n",
            "First 5 rows after preprocessing:\n",
            "   network_speed  files_accessed  suspicious_score  attack_flag  \\\n",
            "0             19              22          0.142137            0   \n",
            "1             25              18          0.011707            0   \n",
            "2             80              30          0.422034            0   \n",
            "3             26               4          0.295041            0   \n",
            "4             32              18          0.486000            0   \n",
            "\n",
            "   device_type_Laptop  device_type_Mobile  device_type_Tablet  \n",
            "0                   1                   0                   0  \n",
            "1                   1                   0                   0  \n",
            "2                   0                   1                   0  \n",
            "3                   0                   0                   1  \n",
            "4                   1                   0                   0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 📌 Step 3:Splitting Data into Training and Testing Sets"
      ],
      "metadata": {
        "id": "7pbpgpHql5Yf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "df = pd.read_csv(\"cyber_data.csv\")\n",
        "\n",
        "# إزالة الأعمدة غير الضرورية\n",
        "df_cleaned = df.drop(columns=[\"timestamp\", \"user_id\"])  # إزالة الأعمدة التي لا تؤثر على التصنيف\n",
        "\n",
        "# تحديد الميزات (X) والمتغير المستهدف (y)\n",
        "X = df_cleaned.drop(columns=[\"attack_flag\"])  # جميع الأعمدة باستثناء \"attack_flag\"\n",
        "y = df_cleaned[\"attack_flag\"]  # العمود المستهدف\n",
        "\n",
        "# تقسيم البيانات إلى 80% تدريب و 20% اختبار\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# طباعة حجم بيانات التدريب والاختبار\n",
        "print(\"Training set size:\", X_train.shape)\n",
        "print(\"Testing set size:\", X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOc08GvzrmBW",
        "outputId": "005c4935-286f-42b7-ccf1-fcb0b2173e7a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: (800, 6)\n",
            "Testing set size: (200, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Training the Machine Learning Model"
      ],
      "metadata": {
        "id": "CtfxaS1rsO30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# إنشاء نموذج Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
        "\n",
        "# تدريب النموذج على بيانات التدريب\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# تأكيد نجاح التدريب\n",
        "print(\"Model Training Completed! ✅\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UR_Mih47sRQ2",
        "outputId": "479656e9-50ab-48d1-9464-86c704359efb"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Training Completed! ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Evaluating the Model\n"
      ],
      "metadata": {
        "id": "Ib8lfcqEssa_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# التنبؤ على بيانات الاختبار\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# حساب دقة النموذج\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# عرض تقرير التصنيف\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# عرض مصفوفة  (Confusion Matrix)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Model Accuracy:\", accuracy)\n",
        "print(\"\\nClassification Report:\\n\", classification_rep)\n",
        "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPVyXhwgsvuP",
        "outputId": "0ddb3e7d-0b3b-49bb-823f-843563159e0d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.88\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.94       176\n",
            "           1       0.00      0.00      0.00        24\n",
            "\n",
            "    accuracy                           0.88       200\n",
            "   macro avg       0.44      0.50      0.47       200\n",
            "weighted avg       0.77      0.88      0.82       200\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[176   0]\n",
            " [ 24   0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Improving the Model\n"
      ],
      "metadata": {
        "id": "Dj2P0fMIs9sZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# تجربة تحسين النموذج باستخدام زيادة عدد الأشجار وتغيير العمق الأقصى\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_improved = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)\n",
        "\n",
        "# إعادة تدريب النموذج\n",
        "rf_improved.fit(X_train, y_train)\n",
        "\n",
        "# التنبؤ باستخدام النموذج المحسن\n",
        "y_pred_improved = rf_improved.predict(X_test)\n",
        "\n",
        "# إعادة حساب دقة النموذج الجديد\n",
        "accuracy_improved = accuracy_score(y_test, y_pred_improved)\n",
        "\n",
        "# إعادة حساب تقرير التصنيف\n",
        "classification_rep_improved = classification_report(y_test, y_pred_improved)\n",
        "\n",
        "# إعادة حساب مصفوفة الارتباك\n",
        "conf_matrix_improved = confusion_matrix(y_test, y_pred_improved)\n",
        "\n",
        "print(\"Improved Model Accuracy:\", accuracy_improved)\n",
        "print(\"\\nImproved Classification Report:\\n\", classification_rep_improved)\n",
        "print(\"\\nImproved Confusion Matrix:\\n\", conf_matrix_improved)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhdQjPFUtVGl",
        "outputId": "b664a859-7f63-4ca7-dfd1-82f811a83963"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Improved Model Accuracy: 0.875\n",
            "\n",
            "Improved Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.99      0.93       176\n",
            "           1       0.00      0.00      0.00        24\n",
            "\n",
            "    accuracy                           0.88       200\n",
            "   macro avg       0.44      0.50      0.47       200\n",
            "weighted avg       0.77      0.88      0.82       200\n",
            "\n",
            "\n",
            "Improved Confusion Matrix:\n",
            " [[175   1]\n",
            " [ 24   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Step 7: Using XGBoost Model"
      ],
      "metadata": {
        "id": "kDZa2ajat3Q8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# تقليل عدد الأشجار إلى 20 وتحسين المعايير لتسريع التدريب\n",
        "xgb_model = XGBClassifier(n_estimators=20, learning_rate=0.1, max_depth=3, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
        "\n",
        "# تقليل حجم بيانات التدريب إلى 30% لتسريع العملية\n",
        "X_train_sample = X_train.sample(frac=0.3, random_state=42)\n",
        "y_train_sample = y_train.loc[X_train_sample.index]\n",
        "\n",
        "# تدريب النموذج\n",
        "xgb_model.fit(X_train_sample, y_train_sample)\n",
        "\n",
        "# التنبؤ على بيانات الاختبار باستخدام XGBoost\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# حساب دقة النموذج\n",
        "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "\n",
        "# تقرير التصنيف\n",
        "classification_rep_xgb = classification_report(y_test, y_pred_xgb)\n",
        "\n",
        "conf_matrix_xgb = confusion_matrix(y_test, y_pred_xgb)\n",
        "print(\"XGBoost Model Accuracy:\", accuracy_xgb)\n",
        "print(\"\\nClassification Report:\\n\", classification_rep_xgb)\n",
        "print(\"\\nConfusion Matrix:\\n\", conf_matrix_xgb)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Og0CG2rwH7L",
        "outputId": "3f58c980-6759-4a31-e6e0-06546458fa2a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Model Accuracy: 0.88\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.94       176\n",
            "           1       0.00      0.00      0.00        24\n",
            "\n",
            "    accuracy                           0.88       200\n",
            "   macro avg       0.44      0.50      0.47       200\n",
            "weighted avg       0.77      0.88      0.82       200\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[176   0]\n",
            " [ 24   0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:00:07] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8: Finalizing and Saving the Model\n"
      ],
      "metadata": {
        "id": "xcZ7p-9Uy4vk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import joblib\n",
        "\n",
        "# حفظ نموذج XGBoost النهائي\n",
        "joblib.dump(xgb_model, \"xgboost_cybercrime_model.pkl\")\n",
        "\n",
        "df_cleaned.to_csv(\"cleaned_cyber_data.csv\", index=False)\n",
        "\n",
        "print(\"Model and cleaned dataset saved successfully! ✅\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYazGgyKzHg_",
        "outputId": "7131195a-5255-487f-ef3c-c85cd95660e6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and cleaned dataset saved successfully! ✅\n"
          ]
        }
      ]
    }
  ]
}